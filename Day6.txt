AWS Bigdata
Trainer: Prashant Nair
===============================================================================================

Agenda
-------
Instantiating and Working on PySpark Notebook
Working with AWS Glue
Working with AWS Athena



Instantiating a PySpark Jupyter Lab
------------------------------------

1. Go to EMR Dashboard
2. Click on Notebooks > Click on Create Notebook
3. Give a name to the notebook
4. Select Create Cluster
4. Keep everything default and click on Create Notebook


Test the notebook and try some pyspark examples



Assignment - USing Transactions Dataset

00000006,10-28-2011,4002190,027.89,Puzzles,Jigsaw Puzzles,Charleston,South Carolina,credit

Header is absent

txnid 
txndate  (Preferred to use string for date as formatting is not standard)
custid
amount
category
subcategory
city
state
txntype


Perform the following tasks
1. Find the total revenue generated based on category
2. Find the total number of transactions done by credit and cash
3. Find the total amount generated by credit 
4. Find the highest selling category
5. Find the lowest selling category



Working with Data warehousing Solutions
=========================================

				Data warehousing Solution	
					   |
		----------------------------------------------------------
		|							 |
	Server-less 						Server-Based 
	Architecture						Architecture

The service provider will take				Here the user is responsible to
care of the underlying cloud infrastructure		maintain the underlying cloud infra
in terms of Scalability, Flexibility,			in terms of Scalability, Flexibility,
Uptime etc 						Uptime etc.


AWS Athena						AWS Redshift



Amazon Athena
=============

- Serverless Interactive Query Service for S3
- Deal with:
	a. Delimited Files
	b. XML
	c. JSON
	d. ORC
	e. Parquet
	f. Avro

- However Athena expects someone to maintain the metadata !

- To maintain the metadata, we will use AWS Glue !!!






Dataset ---> S3 -------->   
			  
				Amazon Athena -----> INteractive QUery !

AWS Glue --> Metadata -->




Lab1: Employee DAtaset with Schema Generation in AWS Glue using Manual Method

employee ----> S3 ------>AWS Glue ------> Athena


1. Create S3 bucket and load data in it
2. Create Metadata for automobile dataset in Glue
	- Go to Glue Dashboard
	- On left hand menu click Databases > Add database > Create database named           'tigeranalytics'
	- Click on Tables > Add Table > Add Table Manually 
		- Give table name as 'employee' and select database 'tigeranalytics' > Next
		- Select Data Store > S3 > Set the Location of dataset > Next
		- Choose Data Format > CSV > Delimiter as , > Next
		- Create Schema with appropriate datatypes > Next
		- Skip Partition Indices as we didnt set any partition key > Next
		- Review the settings > Finish
		

3. Create Athena Instance and connect with metadata for Interactive Query
	- Go to Athena Dashboard and Click on Get Started

 Athena will automatically interact with Glue for Catalog and help provide platform for Interactive Query !




Using Glue Crawler
===================
Automobile Dataset----> S3 ------> AWS Glue ----> Athena


1. Create S3 bucket and load data in it
2. Go to Glue Dashboard > Crawler > Add Crawler. Follow the instructions and connect with the data source at folder level and Run the Crawler.
3. Create Athena Instance and connect with metadata for Interactive Query
	- Go to Athena Dashboard and Click on Get Started

















Create a new database named automobile123 and use manual method to create the table from 
auto-data.csv file

Ensure the database and table is connected to athena



































